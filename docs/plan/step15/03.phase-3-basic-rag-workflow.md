# Phase 3: 기본 RAG 워크플로우

## 1. 목표 및 범위

### 1.1 목표
- LangGraph.js 기반 RAG 워크플로우 구현
- 질문 분류 (question/summary/chitchat/unknown)
- 벡터 검색 및 답변 생성

### 1.2 요구사항 매핑
| 요구사항 ID | 설명 | 수용 기준 |
|-------------|------|----------|
| FR-CB-006 | 질문 분류 기능 | 4종 분류 정확도 90% 이상 |
| FR-CB-007 | 벡터 유사도 검색 | Top-20 관련 문서 검색 성공 |
| FR-CB-008 | RAG 기반 답변 생성 | 검색된 문서 기반 답변 생성 |

### 1.3 선행 조건
- **Phase 1 완료**: LLM Factory
- **Phase 2 완료**: VectorStoreManager, Retriever

### 1.4 아키텍처 참조
- [00-1.architecture.md](./00-1.architecture.md) 섹션 3.4 (LangGraph Workflow)
- [00-2.tech-decisions.md](./00-2.tech-decisions.md) ADR-002, ADR-005

---

## 2. 구현 항목 체크리스트

### 2.1 상태 정의
- [ ] `src/services/chatbot/workflow/state.js` 생성
  - [ ] ChatbotAnnotation 정의 (Annotation.Root)
  - [ ] MessagesAnnotation 확장
  - [ ] queryType, retrievedDocs, currentStep 등 상태 필드

### 2.2 워크플로우 노드 구현
- [ ] `src/services/chatbot/workflow/nodes/classify.js`
  - [ ] Zod 스키마 정의 (type, confidence)
  - [ ] withStructuredOutput() 사용
  - [ ] question/summary/chitchat/unknown 분류

- [ ] `src/services/chatbot/workflow/nodes/retrieve.js`
  - [ ] Retriever 호출 (k=20)
  - [ ] 검색 결과 상태에 저장

- [ ] `src/services/chatbot/workflow/nodes/generate.js`
  - [ ] 시스템 프롬프트 (영어)
  - [ ] 검색 문서 컨텍스트 구성
  - [ ] 스트리밍 답변 생성

### 2.3 프롬프트 정의
- [ ] `src/services/chatbot/workflow/prompts.js` 생성
  - [ ] SYSTEM_PROMPT (영어, 다국어 응답 지시 포함)
  - [ ] CLASSIFY_PROMPT (영어)
  - [ ] GENERATE_PROMPT (영어)

### 2.4 그래프 빌더 구현
- [ ] `src/services/chatbot/workflow/graph.js` 생성
  - [ ] StateGraph 생성
  - [ ] 노드 추가 (classify, retrieve, generate)
  - [ ] 엣지 추가 (START → classify)
  - [ ] 조건부 엣지 (routeByQueryType)
  - [ ] compile() 호출

---

## 3. 상세 구현 가이드

### 3.1 상태 정의

```javascript
// src/services/chatbot/workflow/state.js

import { Annotation, MessagesAnnotation } from "@langchain/langgraph";

export const ChatbotAnnotation = Annotation.Root({
  // 메시지 히스토리
  ...MessagesAnnotation.spec,

  // 질문 분류 결과
  queryType: Annotation({
    reducer: (_, action) => action,
    default: () => "unknown",
  }),

  // 검색된 문서
  retrievedDocs: Annotation({
    reducer: (_, action) => action,
    default: () => [],
  }),

  // 현재 워크플로우 단계
  currentStep: Annotation({
    reducer: (_, action) => action,
    default: () => "",
  }),
});
```

### 3.2 질문 분류 노드

```javascript
// src/services/chatbot/workflow/nodes/classify.js

import { z } from "zod";
import { CLASSIFY_PROMPT } from "../prompts.js";

const classificationSchema = z.object({
  type: z.enum(["question", "summary", "chitchat", "unknown"]),
  confidence: z.number().min(0).max(1),
});

/**
 * 질문 분류 노드
 */
export async function classifyQuery(state, { llm }) {
  const { messages } = state;
  const lastMessage = messages[messages.length - 1];

  const model = llm.withStructuredOutput(classificationSchema);
  const prompt = CLASSIFY_PROMPT.replace("{input}", lastMessage.content);

  const result = await model.invoke(prompt);

  return {
    queryType: result.type,
    currentStep: "classifyQuery",
  };
}
```

### 3.3 문서 검색 노드

```javascript
// src/services/chatbot/workflow/nodes/retrieve.js

/**
 * 문서 검색 노드
 */
export async function retrieveDocs(state, { retriever }) {
  const { messages } = state;
  const lastMessage = messages[messages.length - 1];

  const documents = await retriever.invoke(lastMessage.content);

  return {
    retrievedDocs: documents,
    currentStep: "retrieveDocs",
  };
}
```

### 3.4 답변 생성 노드

```javascript
// src/services/chatbot/workflow/nodes/generate.js

import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import { SYSTEM_PROMPT, GENERATE_PROMPT } from "../prompts.js";

/**
 * 답변 생성 노드
 */
export async function generateAnswer(state, { llm, config }) {
  const { messages, retrievedDocs, queryType } = state;
  const userQuestion = messages[messages.length - 1].content;

  // 컨텍스트 구성
  const context = retrievedDocs
    .map((doc, i) => `[${i + 1}] ${doc.metadata.source}\n${doc.pageContent}`)
    .join("\n\n---\n\n");

  // 시스템 프롬프트
  const systemPrompt = config.chatbot?.systemPrompt || SYSTEM_PROMPT;

  // 생성 프롬프트
  const generatePrompt = GENERATE_PROMPT
    .replace("{context}", context)
    .replace("{question}", userQuestion);

  const response = await llm.invoke([
    new SystemMessage(systemPrompt),
    new HumanMessage(generatePrompt),
  ]);

  return {
    messages: [response],
    currentStep: "generateAnswer",
  };
}
```

### 3.5 프롬프트 정의 (영어)

```javascript
// src/services/chatbot/workflow/prompts.js

export const SYSTEM_PROMPT = `You are a helpful document assistant for DocLight.
Your primary role is to answer questions based on retrieved documents accurately.

CORE PRINCIPLES:
1. Be concise, accurate, and helpful
2. Always cite sources when referencing specific documents
3. If information is uncertain or incomplete, clearly state limitations
4. Format responses with proper Markdown for readability

RESPONSE FORMAT GUIDELINES:
- Use bullet points for lists
- Use code blocks with language tags for code
- Use bold for emphasis on key terms
- Include source references in format: [Source: filename]

LANGUAGE RULE (CRITICAL):
- Detect the user's language from their question
- If the user asks in Korean, respond ENTIRELY in Korean
- If the user asks in English, respond ENTIRELY in English
- Never mix languages in a single response
- When unsure, default to the language of the most recent message`;

export const CLASSIFY_PROMPT = `You are a query classifier for a document Q&A system.
Classify the following user input into exactly one of these categories:

CATEGORIES:
1. "question" - A specific question seeking information from documents
   Examples: "How do I authenticate?", "What is the API endpoint?", "API 키는 어떻게 발급받나요?"

2. "summary" - A request for summarization or overview
   Examples: "Summarize this document", "Give me an overview", "이 문서를 요약해줘"

3. "chitchat" - Casual conversation, greetings, thanks, or off-topic
   Examples: "Hello", "Thank you", "How are you?", "안녕하세요", "감사합니다"

4. "unknown" - Cannot classify or ambiguous input
   Examples: Single words, gibberish, incomplete sentences

EDGE CASES:
- Follow-up questions like "Tell me more" → "question"
- Questions about the system itself → "chitchat"
- Complex multi-part queries → "question"
- Empty or very short input (<3 chars) → "unknown"

User input: {input}

Respond with a JSON object:
{
  "type": "<category>",
  "confidence": <0.0-1.0>,
  "reasoning": "<brief explanation>"
}`;

export const GENERATE_PROMPT = `Generate a comprehensive answer based on the provided documents.

CONTEXT DOCUMENTS:
{context}

USER'S QUESTION: {question}

INSTRUCTIONS:
1. Answer ONLY based on the provided documents
2. If the documents contain relevant information, synthesize a clear answer
3. If documents are partially relevant, acknowledge what you can/cannot answer
4. If no documents are relevant, say: "I couldn't find relevant information in the documents."

RESPONSE STRUCTURE:
- Start with a direct answer to the question
- Provide supporting details from documents
- Include code examples if applicable
- End with source references

EDGE CASES:
- If asked about something not in documents: Be honest about limitations
- If documents conflict: Present both perspectives
- If question is vague: Ask for clarification OR make reasonable assumptions and state them

Generate your response:`;

export const GENERATE_NO_CONTEXT_PROMPT = `The user asked a question, but no relevant documents were found.

USER'S QUESTION: {question}

INSTRUCTIONS:
1. Acknowledge that no relevant documents were found
2. If the question is about general knowledge, provide a brief general answer
3. Suggest the user rephrase their question or provide more context
4. Stay helpful and constructive

LANGUAGE: Match the language of the user's question.

Generate your response:`;

export const CHITCHAT_PROMPT = `Respond to the user's casual message or greeting.

USER MESSAGE: {input}

GUIDELINES:
1. Be friendly and helpful
2. If greeting, greet back and offer assistance
3. If thanking, acknowledge and offer further help
4. Keep responses brief
5. Match the user's language

Generate a brief, friendly response:`;
```

### 3.6 그래프 빌더

```javascript
// src/services/chatbot/workflow/graph.js

import { StateGraph, START, END } from "@langchain/langgraph";
import { ChatbotAnnotation } from "./state.js";
import { classifyQuery } from "./nodes/classify.js";
import { retrieveDocs } from "./nodes/retrieve.js";
import { generateAnswer } from "./nodes/generate.js";

/**
 * 쿼리 타입별 라우팅
 */
function routeByQueryType(state) {
  switch (state.queryType) {
    case "question":
      return "retrieveDocs";
    case "summary":
      return "generateAnswer"; // 요약은 검색 없이
    case "chitchat":
      return "generateAnswer"; // 잡담도 직접 응답
    default:
      return "generateAnswer";
  }
}

/**
 * 챗봇 워크플로우 그래프 생성
 */
export function createChatbotGraph(config, llm, retriever) {
  const workflow = new StateGraph(ChatbotAnnotation)
    .addNode("classifyQuery", (state) => classifyQuery(state, { llm }))
    .addNode("retrieveDocs", (state) => retrieveDocs(state, { retriever }))
    .addNode("generateAnswer", (state) => generateAnswer(state, { llm, config }))
    .addEdge(START, "classifyQuery")
    .addConditionalEdges("classifyQuery", routeByQueryType)
    .addEdge("retrieveDocs", "generateAnswer")
    .addEdge("generateAnswer", END);

  return workflow.compile();
}
```

---

## 4. 테스트 섹션

### 4.1 테스트 시나리오

#### TC-CB-006: 질문 분류
```gherkin
Given LLM이 설정됨
When "API 인증 방법은?" 메시지로 classifyQuery 호출
Then queryType === "question"
  And confidence > 0.8
```

#### TC-CB-007: 벡터 검색
```gherkin
Given VectorStore에 문서가 임베딩됨
When "API 사용법" 쿼리로 retrieveDocs 호출
Then retrievedDocs.length === 20
  And 문서들이 관련성 순으로 정렬됨
```

#### TC-CB-008: 답변 생성
```gherkin
Given 검색된 문서가 있음
When generateAnswer 호출
Then AI 응답이 messages에 추가됨
  And 응답이 검색 문서 내용을 기반으로 함
```

### 4.2 테스트 코드 작성 지침

```javascript
// test/chatbot/workflow.test.js

import { describe, it, expect, vi, beforeEach } from 'vitest';
import { ChatbotAnnotation } from '../../src/services/chatbot/workflow/state.js';
import { classifyQuery } from '../../src/services/chatbot/workflow/nodes/classify.js';
import { retrieveDocs } from '../../src/services/chatbot/workflow/nodes/retrieve.js';
import { generateAnswer } from '../../src/services/chatbot/workflow/nodes/generate.js';
import { HumanMessage } from "@langchain/core/messages";

describe('Workflow Nodes', () => {
  let mockLLM;
  let mockRetriever;

  beforeEach(() => {
    // Mock LLM with structured output
    mockLLM = {
      withStructuredOutput: vi.fn().mockReturnValue({
        invoke: vi.fn().mockResolvedValue({
          type: 'question',
          confidence: 0.95,
        }),
      }),
      invoke: vi.fn().mockResolvedValue({
        content: 'This is a test answer based on the documents.',
      }),
    };

    // Mock Retriever
    mockRetriever = {
      invoke: vi.fn().mockResolvedValue([
        { pageContent: 'Document 1 content', metadata: { source: 'doc1.md' } },
        { pageContent: 'Document 2 content', metadata: { source: 'doc2.md' } },
      ]),
    };
  });

  describe('classifyQuery', () => {
    it('should classify question type correctly', async () => {
      const state = {
        messages: [new HumanMessage('How do I authenticate with the API?')],
      };

      const result = await classifyQuery(state, { llm: mockLLM });

      expect(result.queryType).toBe('question');
      expect(result.currentStep).toBe('classifyQuery');
    });

    it('should handle chitchat classification', async () => {
      mockLLM.withStructuredOutput().invoke.mockResolvedValueOnce({
        type: 'chitchat',
        confidence: 0.9,
      });

      const state = {
        messages: [new HumanMessage('Hello!')],
      };

      const result = await classifyQuery(state, { llm: mockLLM });

      expect(result.queryType).toBe('chitchat');
    });
  });

  describe('retrieveDocs', () => {
    it('should retrieve documents successfully', async () => {
      const state = {
        messages: [new HumanMessage('API usage guide')],
      };

      const result = await retrieveDocs(state, { retriever: mockRetriever });

      expect(result.retrievedDocs).toHaveLength(2);
      expect(result.currentStep).toBe('retrieveDocs');
      expect(mockRetriever.invoke).toHaveBeenCalledWith('API usage guide');
    });
  });

  describe('generateAnswer', () => {
    it('should generate answer with context', async () => {
      const state = {
        messages: [new HumanMessage('What is the API endpoint?')],
        retrievedDocs: [
          { pageContent: 'API endpoint is /api/v1', metadata: { source: 'api.md' } },
        ],
        queryType: 'question',
      };

      const config = { chatbot: {} };

      const result = await generateAnswer(state, { llm: mockLLM, config });

      expect(result.messages).toHaveLength(1);
      expect(result.currentStep).toBe('generateAnswer');
    });
  });
});
```

### 4.3 회귀테스트 실행 조건
- workflow 노드 코드 변경 시
- 프롬프트 변경 시
- @langchain/langgraph 버전 업그레이드 시

---

## 5. 예상 산출물

```
src/
└── services/
    └── chatbot/
        └── workflow/
            ├── state.js
            ├── graph.js
            ├── prompts.js
            └── nodes/
                ├── classify.js
                ├── retrieve.js
                └── generate.js
```

---

## 6. 완료 기준

- [ ] 모든 구현 항목 체크리스트 완료
- [ ] 질문 분류 정확도 90% 이상 (샘플 테스트)
- [ ] 검색 결과 20개 반환 확인
- [ ] 답변 생성 정상 동작
- [ ] 검증 문서 작성 완료
