# Phase 1: 설정 및 LLM Factory

## 1. 목표 및 범위

### 1.1 목표
- config.json5에 chatbot 섹션 스키마 정의 및 검증
- 다중 LLM 제공자(OpenAI, Azure OpenAI, Ollama) 지원 팩토리 구현
- 다중 Embedding 제공자 지원 팩토리 구현

### 1.2 요구사항 매핑
| 요구사항 ID | 설명 | 수용 기준 |
|-------------|------|----------|
| FR-CB-001 | 다중 LLM 제공자 지원 | OpenAI, Azure OpenAI, Ollama 3종 모두 정상 동작 |
| FR-CB-002 | 다중 임베딩 제공자 지원 | OpenAI, Azure OpenAI, Ollama 임베딩 모두 정상 동작 |

### 1.3 선행 조건
- 없음 (최초 Phase)

### 1.4 아키텍처 참조
- [00-1.architecture.md](./00-1.architecture.md) 섹션 3.1, 3.2 (LLM Factory 계층)
- [00-2.tech-decisions.md](./00-2.tech-decisions.md) ADR-001, ADR-002

---

## 2. 구현 항목 체크리스트

### 2.1 설정 스키마 정의
- [ ] `src/utils/config-loader.js` 수정
  - [ ] chatbot 섹션 스키마 정의
  - [ ] LLM 설정 검증 (type, endpoint, apiKey, model, contextLength)
  - [ ] Embedding 설정 검증
  - [ ] Azure OpenAI 전용 필드 검증 (apiVersion, deploymentName)
  - [ ] Ollama apiKey 빈 문자열 허용 처리
  - [ ] RAG 설정 기본값 (chunkSize: 1000, chunkOverlap: 200, retrievalCount: 20)
  - [ ] Context 설정 기본값 (compressionThreshold: 0.7, compressionTarget: 0.1)

### 2.2 LLM Factory 구현
- [ ] `src/services/chatbot/llm-factory.js` 생성
  - [ ] `createLLM(config)` 함수
  - [ ] OpenAI 타입 처리 (ChatOpenAI)
  - [ ] Azure OpenAI 타입 처리 (AzureChatOpenAI)
  - [ ] Ollama 타입 처리 (ChatOllama)
  - [ ] 잘못된 타입 에러 처리

### 2.3 Embedding Factory 구현
- [ ] `src/services/chatbot/embedding-factory.js` 생성
  - [ ] `createEmbeddings(config)` 함수
  - [ ] OpenAI 타입 처리 (OpenAIEmbeddings)
  - [ ] Azure OpenAI 타입 처리 (AzureOpenAIEmbeddings)
  - [ ] Ollama 타입 처리 (OllamaEmbeddings)
  - [ ] 잘못된 타입 에러 처리

### 2.4 의존성 설치
- [ ] package.json 업데이트
  - [ ] @langchain/core ^0.3.x
  - [ ] @langchain/openai ^0.3.x
  - [ ] @langchain/ollama ^0.1.x
  - [ ] zod ^3.x

---

## 3. 상세 구현 가이드

### 3.1 Config Schema 확장

```javascript
// src/utils/config-loader.js 수정

const chatbotLLMSchema = {
  type: { type: 'string', enum: ['openai', 'azure-openai', 'ollama'], required: true },
  endpoint: { type: 'string', required: true },
  apiKey: { type: 'string', required: true }, // ollama는 빈 문자열 허용
  model: { type: 'string', required: true },
  contextLength: { type: 'number', required: true, min: 1000 },
  temperature: { type: 'number', default: 0.7, min: 0, max: 2 },
  maxTokens: { type: 'number', default: 4096 },
  // azure-openai 전용
  apiVersion: { type: 'string', requiredIf: { type: 'azure-openai' } },
  deploymentName: { type: 'string', requiredIf: { type: 'azure-openai' } },
};

const chatbotEmbeddingSchema = {
  type: { type: 'string', enum: ['openai', 'azure-openai', 'ollama'], required: true },
  endpoint: { type: 'string', required: true },
  apiKey: { type: 'string', required: true },
  model: { type: 'string', required: true },
  // azure-openai 전용
  apiVersion: { type: 'string', requiredIf: { type: 'azure-openai' } },
  deploymentName: { type: 'string', requiredIf: { type: 'azure-openai' } },
};

const chatbotSchema = {
  llm: { type: 'object', schema: chatbotLLMSchema, required: true },
  embedding: { type: 'object', schema: chatbotEmbeddingSchema, required: true },
  rag: {
    type: 'object',
    default: { chunkSize: 1000, chunkOverlap: 200, retrievalCount: 20 },
  },
  context: {
    type: 'object',
    default: { compressionThreshold: 0.7, compressionTarget: 0.1 },
  },
  systemPrompt: { type: 'string', default: '' },
};
```

### 3.2 LLM Factory 구현

```javascript
// src/services/chatbot/llm-factory.js

import { ChatOpenAI, AzureChatOpenAI } from "@langchain/openai";
import { ChatOllama } from "@langchain/ollama";

/**
 * LLM 인스턴스 생성 팩토리
 * @param {Object} config - chatbot.llm 설정
 * @returns {BaseChatModel} LLM 인스턴스
 */
export function createLLM(config) {
  const { type, endpoint, apiKey, model, temperature, maxTokens, apiVersion, deploymentName } = config;

  switch (type) {
    case 'openai':
      return new ChatOpenAI({
        model,
        apiKey,
        configuration: { baseURL: endpoint },
        temperature: temperature ?? 0.7,
        maxTokens: maxTokens ?? 4096,
      });

    case 'azure-openai':
      return new AzureChatOpenAI({
        model,
        azureOpenAIApiKey: apiKey,
        azureOpenAIApiEndpoint: endpoint,
        azureOpenAIApiVersion: apiVersion,
        azureOpenAIApiDeploymentName: deploymentName,
        temperature: temperature ?? 0.7,
        maxTokens: maxTokens ?? 4096,
      });

    case 'ollama':
      return new ChatOllama({
        model,
        baseUrl: endpoint,
        temperature: temperature ?? 0.7,
      });

    default:
      throw new Error(`Unsupported LLM type: ${type}. Supported types: openai, azure-openai, ollama`);
  }
}
```

### 3.3 Embedding Factory 구현

```javascript
// src/services/chatbot/embedding-factory.js

import { OpenAIEmbeddings, AzureOpenAIEmbeddings } from "@langchain/openai";
import { OllamaEmbeddings } from "@langchain/ollama";

/**
 * Embedding 인스턴스 생성 팩토리
 * @param {Object} config - chatbot.embedding 설정
 * @returns {Embeddings} Embedding 인스턴스
 */
export function createEmbeddings(config) {
  const { type, endpoint, apiKey, model, apiVersion, deploymentName } = config;

  switch (type) {
    case 'openai':
      return new OpenAIEmbeddings({
        model,
        apiKey,
        configuration: { baseURL: endpoint },
      });

    case 'azure-openai':
      return new AzureOpenAIEmbeddings({
        azureOpenAIApiKey: apiKey,
        azureOpenAIApiEndpoint: endpoint,
        azureOpenAIApiVersion: apiVersion,
        azureOpenAIApiEmbeddingsDeploymentName: deploymentName,
      });

    case 'ollama':
      return new OllamaEmbeddings({
        model,
        baseUrl: endpoint,
      });

    default:
      throw new Error(`Unsupported embedding type: ${type}. Supported types: openai, azure-openai, ollama`);
  }
}
```

---

## 4. 테스트 섹션

### 4.1 테스트 시나리오

#### TC-CB-001: OpenAI LLM 생성
```gherkin
Given chatbot.llm.type이 "openai"로 설정됨
  And endpoint, apiKey, model이 유효하게 설정됨
When createLLM(config)을 호출하면
Then ChatOpenAI 인스턴스가 반환됨
  And 모델명, API 키가 올바르게 설정됨
```

#### TC-CB-001-2: Azure OpenAI LLM 생성
```gherkin
Given chatbot.llm.type이 "azure-openai"로 설정됨
  And apiVersion, deploymentName이 추가로 설정됨
When createLLM(config)을 호출하면
Then AzureChatOpenAI 인스턴스가 반환됨
```

#### TC-CB-001-3: Ollama LLM 생성
```gherkin
Given chatbot.llm.type이 "ollama"로 설정됨
  And apiKey가 빈 문자열임
When createLLM(config)을 호출하면
Then ChatOllama 인스턴스가 반환됨
  And 에러 없이 동작함
```

#### TC-CB-001-4: 잘못된 LLM 타입
```gherkin
Given chatbot.llm.type이 "invalid"로 설정됨
When createLLM(config)을 호출하면
Then "Unsupported LLM type" 에러가 발생함
```

#### TC-CB-002: OpenAI Embedding 생성
```gherkin
Given chatbot.embedding.type이 "openai"로 설정됨
When createEmbeddings(config)을 호출하면
Then OpenAIEmbeddings 인스턴스가 반환됨
```

### 4.2 테스트 코드 작성 지침

```javascript
// test/chatbot/llm-factory.test.js

import { describe, it, expect, vi } from 'vitest';
import { createLLM } from '../../src/services/chatbot/llm-factory.js';
import { createEmbeddings } from '../../src/services/chatbot/embedding-factory.js';

describe('LLM Factory', () => {
  describe('createLLM', () => {
    it('should create ChatOpenAI for openai type', () => {
      const config = {
        type: 'openai',
        endpoint: 'https://api.openai.com/v1',
        apiKey: 'test-key',
        model: 'gpt-4o',
        contextLength: 128000,
      };

      const llm = createLLM(config);

      expect(llm.constructor.name).toBe('ChatOpenAI');
    });

    it('should create AzureChatOpenAI for azure-openai type', () => {
      const config = {
        type: 'azure-openai',
        endpoint: 'https://my-resource.openai.azure.com',
        apiKey: 'test-key',
        model: 'gpt-4o',
        contextLength: 128000,
        apiVersion: '2024-02-01',
        deploymentName: 'gpt-4o',
      };

      const llm = createLLM(config);

      expect(llm.constructor.name).toBe('AzureChatOpenAI');
    });

    it('should create ChatOllama for ollama type', () => {
      const config = {
        type: 'ollama',
        endpoint: 'http://localhost:11434',
        apiKey: '',
        model: 'llama3',
        contextLength: 8192,
      };

      const llm = createLLM(config);

      expect(llm.constructor.name).toBe('ChatOllama');
    });

    it('should throw error for unsupported type', () => {
      const config = { type: 'invalid' };

      expect(() => createLLM(config)).toThrow('Unsupported LLM type');
    });
  });
});
```

### 4.3 회귀테스트 실행 조건

- 설정 파일 변경 시
- LLM/Embedding Factory 코드 변경 시
- @langchain/* 패키지 버전 업그레이드 시

---

## 5. 품질 기준

| 기준 | 목표 | 검증 방법 |
|------|------|----------|
| Plan-Code 정합성 | 100% | 체크리스트 대비 코드 리뷰 |
| 테스트 커버리지 | ≥ 80% | Jest/Vitest 커버리지 리포트 |
| 에러 처리 | 모든 경로 | 잘못된 설정 입력 테스트 |
| 문서화 | JSDoc 완비 | 코드 리뷰 |

---

## 6. 예상 산출물

### 6.1 생성 파일
```
src/
├── services/
│   └── chatbot/
│       ├── llm-factory.js        # LLM 팩토리
│       └── embedding-factory.js  # Embedding 팩토리
└── utils/
    └── config-loader.js          # (수정) chatbot 스키마 추가

test/
└── chatbot/
    ├── llm-factory.test.js
    └── embedding-factory.test.js
```

### 6.2 수정 파일
- `package.json` - 의존성 추가
- `config.example.json5` - chatbot 섹션 예시 추가

---

## 7. DocLight 기존 패턴 준수 가이드

### 7.1 config-loader.js 확장 패턴

기존 DocLight의 `config-loader.js`는 다음 패턴을 따릅니다. chatbot 설정도 동일 패턴으로 추가합니다:

```javascript
// src/utils/config-loader.js - 기존 패턴 예시 (참고)

// 1. 필수 필드 검증
if (config.chatbot && !config.chatbot.llm) {
  throw new Error('Configuration error: chatbot.llm is required when chatbot is enabled');
}

// 2. 기본값 설정 패턴
if (config.chatbot) {
  config.chatbot.rag = {
    chunkSize: 1000,
    chunkOverlap: 200,
    retrievalCount: 20,
    ...config.chatbot.rag  // 사용자 설정 우선
  };
}

// 3. 조건부 필드 검증 (Azure OpenAI)
if (config.chatbot?.llm?.type === 'azure-openai') {
  if (!config.chatbot.llm.apiVersion) {
    throw new Error('Configuration error: chatbot.llm.apiVersion is required for azure-openai');
  }
  if (!config.chatbot.llm.deploymentName) {
    throw new Error('Configuration error: chatbot.llm.deploymentName is required for azure-openai');
  }
}

// 4. Ollama apiKey 빈 문자열 허용
if (config.chatbot?.llm?.type === 'ollama') {
  // apiKey는 빈 문자열 허용 (로컬 환경)
  config.chatbot.llm.apiKey = config.chatbot.llm.apiKey || '';
}

// 5. 경고 메시지 출력 (기존 DocLight 패턴)
if (config.chatbot && !config.chatbot.embedding) {
  console.warn('Warning: chatbot.embedding not configured, chatbot feature will be disabled');
}
```

### 7.2 CommonJS vs ESM 모듈 시스템

DocLight는 현재 **CommonJS** 모듈 시스템을 사용합니다. 새로운 파일도 CommonJS로 작성합니다:

```javascript
// src/services/chatbot/llm-factory.js (CommonJS)

const { ChatOpenAI, AzureChatOpenAI } = require("@langchain/openai");
const { ChatOllama } = require("@langchain/ollama");

function createLLM(config) {
  // ... 구현
}

module.exports = { createLLM };
```

### 7.3 에러 코드 패턴

기존 DocLight의 error-handler.js와 일관된 에러 코드를 사용합니다:

```javascript
// 에러 코드 패턴 (기존 DocLight 호환)
const error = new Error('LLM_CONFIG_INVALID: Invalid LLM configuration');
error.code = 'LLM_CONFIG_INVALID';
throw error;

// 지원하는 에러 코드 목록 (error-handler.js에 추가 필요)
// LLM_CONFIG_INVALID: 400
// LLM_CONNECTION_FAILED: 503
// EMBEDDING_CONFIG_INVALID: 400
// EMBEDDING_CONNECTION_FAILED: 503
```

---

## 8. 완료 기준

- [ ] 모든 구현 항목 체크리스트 완료
- [ ] 모든 테스트 케이스 통과
- [ ] 코드 커버리지 80% 이상
- [ ] config.example.json5 업데이트
- [ ] 검증 문서 작성 완료
- [ ] 기존 DocLight 패턴 준수 확인

---

## 9. Quick Start (AI 구현 가이드)

### 9.1 npm 패키지 설치 명령어

```bash
npm install @langchain/core @langchain/openai @langchain/ollama zod
```

### 9.2 config.example.json5 추가 내용

```json5
// config.example.json5에 추가
{
  // ... 기존 설정 ...

  // 챗봇 설정 (Step 15)
  chatbot: {
    // LLM 설정
    llm: {
      type: "openai",  // "openai" | "azure-openai" | "ollama"
      endpoint: "https://api.openai.com/v1",
      apiKey: "your-api-key-here",  // 실제 API 키로 변경 필요
      model: "gpt-4o",
      contextLength: 128000,
      temperature: 0.7,  // optional, default: 0.7
      maxTokens: 4096,   // optional, default: 4096
      // Azure OpenAI 전용 (type: "azure-openai" 시 필수)
      // apiVersion: "2024-02-01",
      // deploymentName: "gpt-4o",
    },
    // Embedding 설정
    embedding: {
      type: "openai",  // "openai" | "azure-openai" | "ollama"
      endpoint: "https://api.openai.com/v1",
      apiKey: "your-api-key-here",
      model: "text-embedding-3-small",
      // Azure OpenAI 전용 (type: "azure-openai" 시 필수)
      // apiVersion: "2024-02-01",
      // deploymentName: "text-embedding-3-small",
    },
    // RAG 설정 (optional)
    rag: {
      chunkSize: 1000,      // default: 1000
      chunkOverlap: 200,    // default: 200
      retrievalCount: 20,   // default: 20
    },
    // 컨텍스트 관리 설정 (optional)
    context: {
      compressionThreshold: 0.7,  // 70% 초과 시 요약 트리거
      compressionTarget: 0.1,     // 10% 이하로 압축
    },
    // 시스템 프롬프트 (optional)
    systemPrompt: "",  // 빈 문자열 시 기본 프롬프트 사용
  },
}
```

### 9.3 디렉토리 생성 명령어

```bash
mkdir -p src/services/chatbot
mkdir -p test/chatbot
```

### 9.4 구현 순서

1. **config-loader.js 수정**: chatbot 섹션 스키마 추가
2. **llm-factory.js 생성**: LLM 인스턴스 팩토리
3. **embedding-factory.js 생성**: Embedding 인스턴스 팩토리
4. **테스트 코드 작성**: llm-factory.test.js, embedding-factory.test.js
5. **config.example.json5 업데이트**: chatbot 섹션 예시 추가
